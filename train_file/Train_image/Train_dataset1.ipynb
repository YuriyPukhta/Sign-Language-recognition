{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData_Dir = \"D:/project/dataset/sing/asl_alphabet_train/asl_alphabet_train\"\n",
    "\n",
    "# Define the transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((100, 100)),\n",
    "    transforms.RandomRotation(degrees=15),  # Resize images to a fixed size\n",
    "    transforms.ToTensor(),  # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize the images\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(trainData_Dir, transform=train_transform)\n",
    "\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "t , v = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "batch_size = 32\n",
    "shuffle_data = True\n",
    "\n",
    "\n",
    "val_loader = DataLoader(v, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_loader = DataLoader(t, batch_size=batch_size, shuffle=shuffle_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'A',\n",
       " 1: 'B',\n",
       " 2: 'C',\n",
       " 3: 'D',\n",
       " 4: 'del',\n",
       " 5: 'E',\n",
       " 6: 'F',\n",
       " 7: 'G',\n",
       " 8: 'H',\n",
       " 9: 'I',\n",
       " 10: 'J',\n",
       " 11: 'K',\n",
       " 12: 'L',\n",
       " 13: 'M',\n",
       " 14: 'N',\n",
       " 15: 'nothing',\n",
       " 16: 'O',\n",
       " 17: 'P',\n",
       " 18: 'Q',\n",
       " 19: 'R',\n",
       " 20: 'S',\n",
       " 21: 'space',\n",
       " 22: 'T',\n",
       " 23: 'U',\n",
       " 24: 'V',\n",
       " 25: 'W',\n",
       " 26: 'X',\n",
       " 27: 'Y',\n",
       " 28: 'Z'}"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = {}\n",
    "mapper_ = {}\n",
    "for i, dir_name in enumerate(os.listdir(trainData_Dir)):\n",
    "    mapper[i] = dir_name\n",
    "    mapper_[dir_name] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((100, 100)),  # Resize images to a fixed size\n",
    "    transforms.ToTensor(),  # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize the images\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData_Dir = \"D:\\project\\dataset\\ASL_Dataset\\Test\\W\"\n",
    "images = []\n",
    "lables = []\n",
    "for file_name in os.listdir(testData_Dir):\n",
    "    # Get the full path of the file\n",
    "    image_path =os.path.join(testData_Dir, file_name)\n",
    "    image = Image.open(image_path)\n",
    "    transformed_image = test_transform(image)\n",
    "    images.append(transformed_image)\n",
    "    #lable =mapper_[file_name.split(\"_\")[0]]\n",
    "    lables.append(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_t = torch.stack(images)\n",
    "lables_t = torch.tensor(lables, dtype=torch.long)\n",
    "\n",
    "test_dataset = TensorDataset(images_t, lables_t)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yuriy\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yuriy\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\Yuriy/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n",
      " 11%|█▏        | 11.2M/97.8M [00:01<00:09, 9.21MB/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mresnet50(pretrained\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\Yuriy\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchvision\\models\\_utils.py:142\u001b[0m, in \u001b[0;36mkwonly_to_pos_or_kw.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    136\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUsing \u001b[39m\u001b[39m{\u001b[39;00msequence_to_str(\u001b[39mtuple\u001b[39m(keyword_only_kwargs\u001b[39m.\u001b[39mkeys()),\u001b[39m \u001b[39mseparate_last\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mand \u001b[39m\u001b[39m'\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m as positional \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    137\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    138\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minstead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    139\u001b[0m     )\n\u001b[0;32m    140\u001b[0m     kwargs\u001b[39m.\u001b[39mupdate(keyword_only_kwargs)\n\u001b[1;32m--> 142\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Yuriy\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchvision\\models\\_utils.py:228\u001b[0m, in \u001b[0;36mhandle_legacy_interface.<locals>.outer_wrapper.<locals>.inner_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[39mdel\u001b[39;00m kwargs[pretrained_param]\n\u001b[0;32m    226\u001b[0m     kwargs[weights_param] \u001b[39m=\u001b[39m default_weights_arg\n\u001b[1;32m--> 228\u001b[0m \u001b[39mreturn\u001b[39;00m builder(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Yuriy\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchvision\\models\\resnet.py:763\u001b[0m, in \u001b[0;36mresnet50\u001b[1;34m(weights, progress, **kwargs)\u001b[0m\n\u001b[0;32m    737\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"ResNet-50 from `Deep Residual Learning for Image Recognition <https://arxiv.org/pdf/1512.03385.pdf>`__.\u001b[39;00m\n\u001b[0;32m    738\u001b[0m \n\u001b[0;32m    739\u001b[0m \u001b[39m.. note::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    759\u001b[0m \u001b[39m    :members:\u001b[39;00m\n\u001b[0;32m    760\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    761\u001b[0m weights \u001b[39m=\u001b[39m ResNet50_Weights\u001b[39m.\u001b[39mverify(weights)\n\u001b[1;32m--> 763\u001b[0m \u001b[39mreturn\u001b[39;00m _resnet(Bottleneck, [\u001b[39m3\u001b[39;49m, \u001b[39m4\u001b[39;49m, \u001b[39m6\u001b[39;49m, \u001b[39m3\u001b[39;49m], weights, progress, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Yuriy\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchvision\\models\\resnet.py:301\u001b[0m, in \u001b[0;36m_resnet\u001b[1;34m(block, layers, weights, progress, **kwargs)\u001b[0m\n\u001b[0;32m    298\u001b[0m model \u001b[39m=\u001b[39m ResNet(block, layers, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    300\u001b[0m \u001b[39mif\u001b[39;00m weights \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 301\u001b[0m     model\u001b[39m.\u001b[39mload_state_dict(weights\u001b[39m.\u001b[39;49mget_state_dict(progress\u001b[39m=\u001b[39;49mprogress))\n\u001b[0;32m    303\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\Yuriy\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchvision\\models\\_api.py:89\u001b[0m, in \u001b[0;36mWeightsEnum.get_state_dict\u001b[1;34m(self, progress)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state_dict\u001b[39m(\u001b[39mself\u001b[39m, progress: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Mapping[\u001b[39mstr\u001b[39m, Any]:\n\u001b[1;32m---> 89\u001b[0m     \u001b[39mreturn\u001b[39;00m load_state_dict_from_url(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murl, progress\u001b[39m=\u001b[39;49mprogress)\n",
      "File \u001b[1;32mc:\\Users\\Yuriy\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\hub.py:746\u001b[0m, in \u001b[0;36mload_state_dict_from_url\u001b[1;34m(url, model_dir, map_location, progress, check_hash, file_name)\u001b[0m\n\u001b[0;32m    744\u001b[0m         r \u001b[39m=\u001b[39m HASH_REGEX\u001b[39m.\u001b[39msearch(filename)  \u001b[39m# r is Optional[Match[str]]\u001b[39;00m\n\u001b[0;32m    745\u001b[0m         hash_prefix \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mgroup(\u001b[39m1\u001b[39m) \u001b[39mif\u001b[39;00m r \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 746\u001b[0m     download_url_to_file(url, cached_file, hash_prefix, progress\u001b[39m=\u001b[39;49mprogress)\n\u001b[0;32m    748\u001b[0m \u001b[39mif\u001b[39;00m _is_legacy_zip_format(cached_file):\n\u001b[0;32m    749\u001b[0m     \u001b[39mreturn\u001b[39;00m _legacy_zip_load(cached_file, model_dir, map_location)\n",
      "File \u001b[1;32mc:\\Users\\Yuriy\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\hub.py:633\u001b[0m, in \u001b[0;36mdownload_url_to_file\u001b[1;34m(url, dst, hash_prefix, progress)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mwith\u001b[39;00m tqdm(total\u001b[39m=\u001b[39mfile_size, disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m progress,\n\u001b[0;32m    631\u001b[0m           unit\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mB\u001b[39m\u001b[39m'\u001b[39m, unit_scale\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, unit_divisor\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m) \u001b[39mas\u001b[39;00m pbar:\n\u001b[0;32m    632\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 633\u001b[0m         buffer \u001b[39m=\u001b[39m u\u001b[39m.\u001b[39;49mread(\u001b[39m8192\u001b[39;49m)\n\u001b[0;32m    634\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(buffer) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    635\u001b[0m             \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yuriy\\AppData\\Local\\Programs\\Python\\Python38\\lib\\http\\client.py:454\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    452\u001b[0m     \u001b[39m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[0;32m    453\u001b[0m     b \u001b[39m=\u001b[39m \u001b[39mbytearray\u001b[39m(amt)\n\u001b[1;32m--> 454\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[0;32m    455\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmemoryview\u001b[39m(b)[:n]\u001b[39m.\u001b[39mtobytes()\n\u001b[0;32m    456\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    457\u001b[0m     \u001b[39m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[0;32m    458\u001b[0m     \u001b[39m# and self.chunked\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yuriy\\AppData\\Local\\Programs\\Python\\Python38\\lib\\http\\client.py:498\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    493\u001b[0m         b \u001b[39m=\u001b[39m \u001b[39mmemoryview\u001b[39m(b)[\u001b[39m0\u001b[39m:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength]\n\u001b[0;32m    495\u001b[0m \u001b[39m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[0;32m    496\u001b[0m \u001b[39m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \u001b[39m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[1;32m--> 498\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[0;32m    499\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m n \u001b[39mand\u001b[39;00m b:\n\u001b[0;32m    500\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    501\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    502\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mc:\\Users\\Yuriy\\AppData\\Local\\Programs\\Python\\Python38\\lib\\socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    667\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    668\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 669\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    670\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    671\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yuriy\\AppData\\Local\\Programs\\Python\\Python38\\lib\\ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1238\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1239\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1240\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1242\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1243\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\Yuriy\\AppData\\Local\\Programs\\Python\\Python38\\lib\\ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1098\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1099\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1100\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1101\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = torchvision.models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(20000, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN(29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yuriy\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yuriy\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "resNet = models.resnet34(pretrained=True)\n",
    "class MyResNet(nn.Module):\n",
    "    def __init__(self, model, froze):\n",
    "        super(MyResNet, self).__init__()\n",
    "        if(froze):\n",
    "          for param in model.parameters():\n",
    "              param.requires_grad = False\n",
    "        self.model = torch.nn.Sequential(*list(model.children())[:-1])\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l = nn.Linear(512, 29)\n",
    "        self.dropout = nn.Dropout2d(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, _, _, _ = x.shape\n",
    "        x = self.model(x)\n",
    "        x = F.adaptive_avg_pool2d(x, 1).reshape(batch, -1)\n",
    "        x = self.dropout(x)\n",
    "        res = self.l(x)\n",
    "        return res\n",
    "\n",
    "myResNet = MyResNet(resNet, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"D:/project/asl/checkpoint.pt\"\n",
    "\n",
    "def save_model(model):\n",
    "    torch.save(model.state_dict(), checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.to(device)\n",
    "opt_myCNN = optim.Adam(model.parameters(), lr = 0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=20000, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=29, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader):\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_running_correct = 0\n",
    "    val_running_errors = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(dataloader), total=int(len(dataloader.dataset)/dataloader.batch_size)):\n",
    "            #print(data[0].shape)\n",
    "            data, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "            #print(outputs)\n",
    "            #print(labels)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item()* data.size(0)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            val_running_correct += torch.sum(preds == labels)\n",
    "            val_running_errors += torch.sum(preds != labels)\n",
    "\n",
    "        val_loss = val_running_loss/len(dataloader.dataset)\n",
    "        val_accuracy = val_running_correct/len(dataloader.dataset)\n",
    "        val_errore = val_running_errors/len(dataloader.dataset)\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy}')\n",
    "        \n",
    "        return val_loss, val_accuracy, val_errore\n",
    "# train part\n",
    "def train(model,optimizer, dataloader):\n",
    "    model.train()\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0\n",
    "    train_running_errors = 0\n",
    "    for i, data in tqdm(enumerate(dataloader), total=int(len(dataloader.dataset) /dataloader.batch_size)):\n",
    "        #print(data[1])\n",
    "        data, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        train_running_errors += torch.sum(preds != labels)\n",
    "        train_running_correct += torch.sum(preds == labels)\n",
    "        train_running_loss += loss.item()* data.size(0)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss = train_running_loss/len(dataloader.dataset)\n",
    "    train_accuracy = train_running_correct/len(dataloader.dataset)\n",
    "    train_errore = train_running_errors/len(dataloader.dataset)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy}\")\n",
    "    return train_loss, train_accuracy, train_errore\n",
    " #  main \n",
    "def model_train(model, optimizer, train_dataloader ,test_dataloader, epochs):\n",
    "  err_history = {\"train\" : [], \"val\" : []}\n",
    "  acc_history =  {\"train\" : [], \"val\" : []}\n",
    "  loss_history = {\"train\" : [], \"val\" : []}\n",
    "  for epoch in range(epochs):\n",
    "      print(f\"Epoch {epoch+1} of {epochs}\")\n",
    "      phase = \"train\"\n",
    "      print(phase)\n",
    "      loss, accuracy, error = train(model, optimizer, train_dataloader)\n",
    "      err_history[phase].append(error)\n",
    "      acc_history[phase].append(accuracy)\n",
    "      loss_history[phase].append(loss)\n",
    "      phase = \"val\"\n",
    "      print(phase)\n",
    "      loss, accuracy, error = validate(model, test_dataloader)\n",
    "      err_history[phase].append(error)\n",
    "      acc_history[phase].append(accuracy)\n",
    "      loss_history[phase].append(loss)\n",
    "  save_model(model)\n",
    "  return err_history, acc_history, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 2\n",
      "train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2447it [10:39,  3.83it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.2818, Train Acc: 0.30832695960998535\n",
      "val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "272it [01:00,  4.47it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3559, Val Acc: 0.6277011632919312\n",
      "Epoch 2 of 2\n",
      "train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2447it [03:53, 10.50it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3443, Train Acc: 0.5569859743118286\n",
      "val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "272it [00:18, 14.54it/s]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.8091, Val Acc: 0.7822988629341125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "myCNN_err_history, myCNN_acc_history , myCNN_loss_history = model_train(model, opt_myCNN, train_loader, val_loader ,num_epochs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_(model, optimizer, dataloader):\n",
    "    model.eval()\n",
    "    print(\"1\")\n",
    "    val_running_loss = 0.0\n",
    "    val_running_correct = 0\n",
    "    val_running_errors = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(dataloader), total=int(len(dataloader.dataset)/dataloader.batch_size)):\n",
    "            #print(data[0].shape)\n",
    "            data, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "            #print(labels)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item()* data.size(0)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            #print(preds)\n",
    "            val_running_correct += torch.sum(preds == labels)\n",
    "            val_running_errors += torch.sum(preds != labels)\n",
    "\n",
    "        val_loss = val_running_loss/len(dataloader.dataset)\n",
    "        val_accuracy = val_running_correct/len(dataloader.dataset)\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy}')\n",
    "        \n",
    "        return outputs, labels, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "272it [00:51,  5.30it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2687, Val Acc: 0.9111494421958923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.3707e+01, -7.3577e+00, -2.8976e+01, -2.1046e+01, -1.2819e+01,\n",
       "          -1.6865e+01, -1.5723e+01, -2.9239e+01, -1.4102e+01, -2.7500e+01,\n",
       "          -5.8300e+00, -2.3414e+01, -2.1396e+01, -2.4804e+01, -1.4026e+01,\n",
       "          -3.5189e+01, -2.5664e+01, -6.8277e+00, -7.8694e+00, -1.8882e+00,\n",
       "          -4.1162e+00,  4.0520e+00,  4.9129e+00,  3.8504e+00,  1.7671e+00,\n",
       "           1.3478e+00, -1.7756e+01, -1.1727e+01, -6.2857e+00],\n",
       "         [-3.0261e+01, -3.3771e+01, -1.6869e+01, -2.1579e+01, -2.0277e+01,\n",
       "          -1.8472e+01,  8.7345e+00,  1.0297e+01, -1.0017e+01,  7.2036e+00,\n",
       "          -1.7011e+01, -3.1334e+01, -2.6127e+01, -1.3679e+01, -2.6391e+01,\n",
       "           5.7676e+00, -4.4864e+00, -1.5943e+01, -2.2357e+01, -3.1205e+01,\n",
       "          -1.9504e+01, -1.4486e+01, -2.5741e+01, -1.0493e+01, -3.1590e+00,\n",
       "          -3.1030e+01, -1.3413e+00, -1.9823e+01,  5.0195e-01],\n",
       "         [-4.7278e+00, -2.9115e+01, -1.4662e+00, -1.2794e+01, -1.7192e+01,\n",
       "          -1.6715e+01, -1.9474e+01, -2.7534e+01, -2.2381e+01, -2.4701e+01,\n",
       "          -4.0364e+01, -3.2300e+00, -2.0495e+01, -1.3876e+01, -8.3821e+00,\n",
       "          -1.0504e+01, -7.8064e-01, -3.7971e+01, -1.1298e+00,  2.9604e+00,\n",
       "          -2.9161e+01, -2.7912e+01, -3.0739e+01, -6.2846e+00,  3.5294e+00,\n",
       "           1.1835e+01, -6.0186e+00, -5.7490e+00, -1.2319e+01],\n",
       "         [-1.1338e+01, -1.3440e+01, -1.0057e+01, -1.3947e+01, -1.1294e+01,\n",
       "          -1.2405e+01, -8.1059e+00, -1.0875e+01, -1.0818e+01, -6.4627e+00,\n",
       "          -1.5379e+01, -1.7957e+01, -4.9640e+00,  6.1154e-01, -1.1033e+00,\n",
       "          -8.7660e+00, -4.2401e+00, -1.8315e+00, -2.1953e-01, -3.4957e+00,\n",
       "          -1.9370e-01, -2.5506e+00, -5.1275e+00,  9.7690e-01,  8.0229e-01,\n",
       "          -4.8908e+00,  4.1993e+00, -7.2064e+00,  2.7428e+00],\n",
       "         [-1.2940e+01, -9.0802e+00, -6.5788e+00,  1.1666e+00, -4.0997e+00,\n",
       "          -1.3357e+00, -1.2030e+01, -1.7443e+01, -2.5728e+00, -1.5713e+01,\n",
       "          -4.2395e+00,  8.3860e+00, -8.8215e+00, -1.3958e+01,  3.3674e-01,\n",
       "          -1.3203e+01, -1.2391e+01, -1.0640e+01, -1.8619e+01, -7.0409e+00,\n",
       "          -1.8597e+01, -1.4700e+01, -1.8232e+01, -1.7845e+01, -1.5516e+01,\n",
       "          -1.0416e+01, -1.5958e+01, -1.7810e+01, -2.2365e+01],\n",
       "         [-2.5080e+01, -2.9293e+01, -1.9735e+01, -2.0807e+01, -2.1063e+01,\n",
       "          -9.2119e+00,  3.3418e-01,  2.4324e+00, -7.6225e+00,  8.5647e+00,\n",
       "          -8.4349e+00, -2.5214e+01, -1.8294e+01, -1.3918e+01, -1.3657e+01,\n",
       "           2.3090e-01, -4.8460e+00, -1.6878e+01, -2.3320e+01, -1.9109e+01,\n",
       "          -1.0695e+01, -3.3914e+00, -1.1849e+01, -8.5728e+00,  5.7121e+00,\n",
       "          -2.6566e+01, -6.6582e+00, -2.2896e+01,  1.1891e+01],\n",
       "         [-2.6973e+01, -3.4310e+01, -3.4670e+01, -4.5502e+01, -2.0119e+01,\n",
       "          -4.0023e+01,  2.4585e+01,  8.9519e+00, -2.4282e+01, -1.9373e+00,\n",
       "          -2.5582e+01, -5.8289e+01, -3.1467e+01, -2.9387e+01, -5.5899e+01,\n",
       "          -3.7846e+00, -3.2072e+01, -4.9848e+01, -3.3208e+01, -5.0060e+01,\n",
       "          -3.3062e+01, -3.4812e+01, -4.8641e+01, -2.3088e+01, -1.8869e+01,\n",
       "          -7.4614e+01, -2.4205e+01, -2.0208e+01, -1.4006e+01],\n",
       "         [-1.0772e+01, -8.6857e+00, -1.1999e+01, -7.9180e+00, -7.4735e+00,\n",
       "          -7.9690e+00, -1.4503e+01, -1.6198e+01, -8.4348e+00, -5.8105e+00,\n",
       "          -1.4774e+01, -1.1115e+01,  7.3173e+00,  4.2665e+00,  4.9170e+00,\n",
       "          -9.9829e+00, -9.1191e+00, -5.4474e+00, -2.7399e+00, -5.1478e+00,\n",
       "          -2.1171e+00, -4.3902e+00, -6.2554e+00, -6.5534e+00, -8.0648e+00,\n",
       "          -1.1074e+01, -1.2241e+01, -1.6472e+01, -1.0610e+01],\n",
       "         [-3.0584e+00, -1.7657e+01, -1.9665e+01, -1.6220e+01,  4.6508e-02,\n",
       "          -2.2760e+01, -1.1185e+01, -1.9188e+01, -1.4471e+01, -1.5339e+01,\n",
       "          -1.1587e+01, -4.5366e+00,  1.9439e+01,  1.2836e+01, -1.0787e+00,\n",
       "          -2.1460e+01, -3.5920e+01, -1.0268e+01,  5.9049e+00, -2.1241e+01,\n",
       "          -1.1322e+01, -2.7551e+01, -2.2502e+01, -1.9125e+01, -1.2588e+01,\n",
       "          -2.1605e+01, -1.7030e+01, -9.2996e+00, -3.3162e+01],\n",
       "         [ 6.5392e+00,  5.7823e+00, -1.9612e+00,  3.7345e+00,  5.7216e+00,\n",
       "          -3.9699e+00, -3.5465e+00, -1.2529e+01, -3.4422e+00, -1.9034e+01,\n",
       "          -2.6628e+00, -9.6223e+00, -2.1049e+00, -1.3372e+01, -6.3787e+00,\n",
       "          -2.5375e+01, -2.1488e+01, -1.5986e+01, -1.4886e+01, -1.1244e+01,\n",
       "          -8.8949e+00, -1.1078e+01, -7.6065e+00, -8.9599e+00, -1.9091e+01,\n",
       "          -7.2938e+00, -1.5201e+01, -2.1892e+00, -1.6288e+01],\n",
       "         [-3.5694e+01, -3.7205e+01, -1.4401e+01, -2.2797e+01, -2.2608e+01,\n",
       "          -1.8186e+01,  8.0590e+00,  1.3249e+01, -5.8946e+00,  9.6420e+00,\n",
       "          -1.1678e+01, -3.0111e+01, -1.7343e+01, -3.9492e+00, -1.4484e+01,\n",
       "           7.7171e+00, -1.7276e+00, -1.1221e+01, -2.6634e+01, -3.8962e+01,\n",
       "          -2.1529e+01, -1.5648e+01, -3.0501e+01, -1.3631e+01, -8.3187e+00,\n",
       "          -3.4318e+01,  4.9202e+00, -2.2640e+01, -3.9230e+00],\n",
       "         [-4.8118e+00, -5.2920e+00, -5.5666e+00,  8.0001e+00,  9.3381e-01,\n",
       "           9.1052e-01, -1.0311e+01, -1.1545e+01,  1.0425e+00, -9.3404e+00,\n",
       "          -2.7957e+00,  2.6304e+00, -2.4456e-01, -4.8853e+00,  2.9580e+00,\n",
       "          -1.5183e+01, -1.2812e+01, -9.9947e+00, -8.1799e+00, -8.0259e+00,\n",
       "          -1.4374e+01, -1.4621e+01, -1.2741e+01, -1.6278e+01, -1.2940e+01,\n",
       "          -8.4395e+00, -1.6022e+01, -1.0545e+01, -2.1389e+01],\n",
       "         [-1.0538e+01, -1.8058e+00, -2.2658e+01, -9.5213e+00, -6.7326e+00,\n",
       "          -1.8788e+00, -1.3620e+01, -2.5394e+01, -6.0415e+00, -1.7205e+01,\n",
       "           2.8607e+00, -1.1530e+01, -1.0307e+01, -1.5670e+01, -7.2203e+00,\n",
       "          -2.8785e+01, -2.2028e+01,  1.3904e+00, -1.3625e+01, -5.3622e+00,\n",
       "           3.1668e+00,  9.2471e+00,  7.3107e+00, -3.3086e+00, -4.6172e+00,\n",
       "          -1.1260e+00, -9.4696e+00, -1.9308e+01, -9.1892e+00],\n",
       "         [-1.0083e+01, -7.2257e+00, -1.3056e+01, -1.0994e+01, -8.6321e+00,\n",
       "          -8.4569e+00, -4.4964e+00, -1.0688e+01, -7.2068e+00, -8.3029e+00,\n",
       "          -6.5754e-01, -1.5915e+01, -9.6508e+00, -1.0922e+01, -8.3221e+00,\n",
       "          -1.3351e+01, -1.1157e+01, -9.1234e-01, -9.7801e+00, -6.4606e+00,\n",
       "           1.8454e+00,  6.1408e+00,  1.2513e+00,  9.2106e-01, -7.1785e-01,\n",
       "          -4.7598e+00, -2.8230e+00, -1.2008e+01,  8.6064e-01],\n",
       "         [ 2.7737e+00,  6.4633e-01, -7.9576e+00, -2.7296e+00, -6.9966e-02,\n",
       "          -7.2431e+00, -8.0941e+00, -1.2722e+01, -1.0062e+01, -1.0473e+01,\n",
       "          -8.7498e+00, -4.7286e+00,  1.7735e+00, -5.0765e-01, -1.7286e+00,\n",
       "          -9.8043e+00, -1.1121e+01, -4.4864e+00,  1.4619e+00, -2.2030e+00,\n",
       "           1.7424e+00, -2.4700e+00, -2.4000e+00, -5.2058e+00, -4.3244e+00,\n",
       "          -6.9777e+00, -8.4529e+00, -3.7344e+00, -2.7422e+00],\n",
       "         [-2.8614e+01, -3.0045e+01, -1.4581e+01, -1.9412e+01, -1.8892e+01,\n",
       "          -1.9252e+01,  6.0361e+00,  1.4578e+01,  2.6103e+00,  1.2732e+01,\n",
       "          -3.6108e+00, -2.8506e+01, -1.6562e+01, -9.3366e+00, -1.2985e+01,\n",
       "           7.3014e-01, -6.7993e+00, -7.5599e+00, -2.3586e+01, -2.2660e+01,\n",
       "          -1.2851e+01, -1.2692e+01, -2.6673e+01, -8.3323e+00, -7.4570e+00,\n",
       "          -3.4356e+01, -1.5652e+00, -8.3599e+00, -1.2814e+00],\n",
       "         [-8.1560e-02,  1.4027e+00, -6.5710e+00,  4.1856e-01,  1.4900e+00,\n",
       "          -5.7083e+00, -8.0492e+00, -1.2654e+01, -7.3694e+00, -1.1388e+01,\n",
       "          -1.1283e+01, -5.9118e+00, -1.2013e+00, -5.5826e+00, -5.0532e+00,\n",
       "          -1.0548e+01, -1.3044e+01, -8.6775e+00,  1.5657e+00, -1.9841e+00,\n",
       "          -4.8353e-01, -3.6732e+00, -3.7703e+00, -3.3114e+00, -2.2315e+00,\n",
       "          -3.3750e+00, -9.0208e+00, -7.7451e+00, -3.5902e+00],\n",
       "         [-1.4676e+01, -6.2916e+00, -1.9402e+01, -8.3622e+00, -8.9390e+00,\n",
       "          -8.2968e+00, -1.4677e+01, -2.2202e+01, -1.0775e+01, -1.1799e+01,\n",
       "          -4.0661e+00, -7.0218e+00, -2.3020e+00,  1.1013e+00,  2.4914e+00,\n",
       "          -1.7419e+01, -1.2268e+01,  8.6018e+00,  1.9750e+00, -6.5288e+00,\n",
       "           1.4408e+00, -1.5107e+00, -4.9249e+00, -6.6535e+00, -9.5701e+00,\n",
       "          -7.6959e+00, -8.0346e+00, -1.0144e+01, -1.2036e+01],\n",
       "         [-1.0163e+01, -9.4713e+00, -1.3791e+01, -1.4200e+01, -1.1519e+01,\n",
       "          -1.0962e+01, -1.5126e+01, -1.9033e+01, -1.2104e+01, -1.2020e+01,\n",
       "          -1.2613e+01, -1.1233e+01, -4.6571e+00, -1.8067e+00, -1.9227e+00,\n",
       "          -1.4608e+01, -9.5232e+00, -2.2624e+00,  1.8535e+00,  2.6171e+00,\n",
       "           2.5973e+00,  3.3658e+00,  2.0164e+00,  4.1495e+00,  4.0499e+00,\n",
       "           3.2343e+00, -1.2471e+00, -6.8379e+00, -8.0375e-01],\n",
       "         [-1.2536e+01, -7.0105e+00, -1.7208e+01, -3.7833e+00, -2.4612e+00,\n",
       "          -3.4580e+00, -3.0844e+00, -7.1607e+00,  4.1012e+00, -4.8151e+00,\n",
       "           4.3478e+00, -1.0612e+01, -1.0323e+01, -1.2830e+01, -1.0478e+01,\n",
       "          -1.5892e+01, -1.0400e+01,  3.6706e+00, -1.3156e+01, -9.2601e+00,\n",
       "          -4.7719e+00, -2.3082e+00, -4.5135e+00, -8.3969e-02, -6.3758e+00,\n",
       "          -4.5689e+00, -8.1009e-01, -1.0730e+01, -7.6970e+00],\n",
       "         [-8.1002e+00, -1.6375e+01, -8.8173e+00, -7.9079e+00, -6.3503e+00,\n",
       "          -1.0160e+01, -1.0052e+01, -1.3805e+01, -1.3781e+01, -9.5550e+00,\n",
       "          -1.1027e+01, -9.4329e-01,  8.8323e+00,  7.3403e+00,  5.6155e+00,\n",
       "          -1.1815e+00, -1.2816e+01, -7.7452e+00, -3.5923e+00, -1.6626e+01,\n",
       "          -1.1954e+01, -1.4935e+01, -1.3905e+01, -1.4959e+01, -1.1091e+01,\n",
       "          -1.3807e+01, -3.0237e+00, -5.1662e+00, -1.8722e+01],\n",
       "         [-2.0391e+01, -4.0201e+01,  3.7686e+00,  1.2748e+01, -4.6502e+00,\n",
       "           3.3295e+01, -2.7584e+01, -4.2989e+01, -3.6904e+01, -4.1148e+01,\n",
       "          -5.6118e+01,  1.2456e+01, -2.9781e+01, -3.5598e+01,  1.4236e+01,\n",
       "          -1.0467e+01, -1.0393e+01, -8.5506e+01, -3.1267e+01, -5.4688e+00,\n",
       "          -6.4155e+01, -4.1810e+01, -3.5686e+01, -3.7055e+01, -3.8013e+00,\n",
       "          -1.8333e+01, -2.9657e+01, -6.8582e+01, -3.8260e+01],\n",
       "         [-1.0466e+00,  2.0989e+00, -1.4735e+01,  5.2049e-01,  3.1632e+00,\n",
       "          -7.5431e-01, -1.2520e+01, -2.0784e+01, -4.1303e+00, -1.5981e+01,\n",
       "          -2.6835e+00, -4.9275e+00, -2.5310e+00, -1.0341e+01, -4.2456e+00,\n",
       "          -2.1267e+01, -1.7307e+01, -4.1736e+00, -8.5145e+00, -2.9553e+00,\n",
       "          -2.1619e+00, -6.2454e-01,  3.6810e+00, -5.2037e+00, -8.4936e+00,\n",
       "          -5.7673e+00, -1.4111e+01, -1.2663e+01, -1.0757e+01],\n",
       "         [-3.5199e-01,  1.4310e+00, -1.0179e+01, -8.5065e-01,  2.1362e+00,\n",
       "          -1.7891e+00, -8.9694e+00, -1.3967e+01, -6.6039e+00, -1.0659e+01,\n",
       "          -7.0174e+00, -3.1167e+00, -3.4130e+00, -7.4748e+00, -8.3908e+00,\n",
       "          -1.1629e+01, -1.2820e+01, -7.7451e+00, -2.6875e-01, -1.3285e+00,\n",
       "          -4.0085e-01, -2.0231e+00, -1.4045e+00, -4.1031e+00, -2.5105e+00,\n",
       "          -6.4691e+00, -9.5281e+00, -1.1339e+01, -4.4031e+00],\n",
       "         [-5.4788e+00, -7.0349e+00, -8.5699e+00, -1.0462e+01, -6.1661e+00,\n",
       "          -1.0831e+01, -3.8400e+00, -6.2539e+00, -6.6884e+00, -1.0581e+01,\n",
       "          -8.9716e+00, -1.6081e+01, -8.7192e+00, -6.7678e+00, -9.4706e+00,\n",
       "          -1.3836e+01, -1.3455e+01, -6.3693e+00, -2.4571e+00, -3.1210e+00,\n",
       "          -5.4573e-01,  1.8239e-01, -4.8103e+00,  4.4043e+00, -2.7943e+00,\n",
       "          -3.5569e+00, -4.2044e+00, -2.6763e+00, -2.1093e+00],\n",
       "         [-1.3396e+01, -4.5720e+00, -1.9025e+01, -6.9145e+00, -8.3071e+00,\n",
       "          -7.4535e+00, -1.7181e+01, -2.3867e+01, -1.2134e+01, -1.4379e+01,\n",
       "          -3.2918e+00, -5.4388e+00, -5.1335e+00, -1.6198e+00,  1.5750e+00,\n",
       "          -2.0233e+01, -1.4042e+01,  9.2536e+00,  1.2822e-01, -5.5956e+00,\n",
       "           6.2021e-01, -1.2690e+00, -5.1355e+00, -8.9155e+00, -1.0518e+01,\n",
       "          -8.9108e+00, -1.1267e+01, -1.4801e+01, -1.5974e+01],\n",
       "         [-1.3967e+01, -1.3560e+01, -1.4786e+00, -5.8215e+00, -5.5371e+00,\n",
       "          -6.5840e+00, -1.4659e+00, -7.9791e-01, -1.2049e+01, -1.6721e+00,\n",
       "          -1.3232e+01, -1.1442e+01, -1.0910e+01, -4.3509e+00, -3.7931e+00,\n",
       "           5.6439e+00,  3.5340e+00, -9.7289e+00, -3.5620e+00, -1.3486e+01,\n",
       "          -9.5055e+00, -9.5980e+00, -1.3999e+01, -5.7923e+00, -2.8075e-01,\n",
       "          -1.0167e+01,  4.2137e+00, -3.9012e+00,  1.3419e+00],\n",
       "         [-1.1776e+01, -1.0171e+01, -2.2231e+01, -1.7271e+01, -1.6420e+01,\n",
       "          -1.9812e+01, -1.6406e+01, -2.8581e+01, -1.7010e+01, -2.0750e+01,\n",
       "          -8.9963e+00, -1.9257e+01, -9.4330e+00, -3.9675e+00, -4.2941e+00,\n",
       "          -2.7330e+01, -1.9926e+01,  2.7482e+00,  3.1500e+00, -1.3088e-01,\n",
       "           8.2816e+00,  5.6957e+00,  1.0231e+00,  2.1485e+00, -1.6749e+00,\n",
       "          -1.6948e+00, -7.6330e+00, -6.3385e+00, -5.5902e+00]], device='cuda:0'),\n",
       " tensor([22,  7, 25, 26, 11, 28,  6, 14, 12,  1,  7,  3, 21, 21, 20,  7,  4, 17,\n",
       "         24, 10, 12,  5, 22,  4, 23, 17, 15, 20], device='cuda:0'),\n",
       " tensor([22,  7, 25, 26, 11, 28,  6, 12, 12,  0,  7,  3, 21, 21,  0,  7, 18, 17,\n",
       "         23, 10, 12,  5, 22,  4, 23, 17, 15, 20], device='cuda:0'))"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_(model, _ , val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 20.5002, Val Acc: 0.1785714328289032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = [0]*29\n",
    "for e in val_loader.dataset:\n",
    "    count[e[1]] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 66.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 8.1486, Val Acc: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs, leble, pred  = validate_(model, _ , test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(22, device='cuda:0')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, \n",
    "                      normalized=False, \n",
    "                      title=None, \n",
    "                      cmap=plt.cm.Blues,\n",
    "                      size=(16,12)):\n",
    "    fig, ax = plt.subplots(figsize=size)\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        3, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 2, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 3, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 3, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 4]], dtype=int64)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = SimpleCNN(29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=9216, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=29, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_state_dict = torch.load(checkpoint_path)\n",
    "\n",
    "model_test.load_state_dict(saved_state_dict)\n",
    "model_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87000"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 3.3891, Val Acc: 0.0357142873108387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "out, lab, preds =  validate_(model, \"8\" ,test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
       "        28, 28, 28, 28, 28, 28, 28, 28, 28, 28], device='cuda:0')"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  5,  6,  7,  8,  9, 10, 11, 12, 13, 15, 14, 16, 17, 18,\n",
       "        19, 21, 20, 22, 23, 24, 25, 26, 27, 28], device='cuda:0')"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[168], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_dataset[:,\u001b[39m0\u001b[39;49m]\n",
      "File \u001b[1;32mc:\\Users\\Yuriy\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\dataset.py:196\u001b[0m, in \u001b[0;36mTensorDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index):\n\u001b[1;32m--> 196\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39;49m(tensor[index] \u001b[39mfor\u001b[39;49;00m tensor \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtensors)\n",
      "File \u001b[1;32mc:\\Users\\Yuriy\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\dataset.py:196\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index):\n\u001b[1;32m--> 196\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(tensor[index] \u001b[39mfor\u001b[39;00m tensor \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtensors)\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "test_dataset[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_R  =model_test(images_t.to(device))\n",
    "loss = criterion(out_R, lables_t.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  25.1246,  -17.7779,  -30.0222,  -46.3044,  -13.8914,  -13.6885,\n",
       "          -33.4458,  -59.6534,  -17.4975,  -46.3703,  -45.5736,   -0.7717,\n",
       "          -10.1311,  -16.1549,   -4.7489,  -39.6303,  -25.6147,  -51.9624,\n",
       "            8.8614,   27.1093,  -26.5826,  -34.8662,  -16.8425,   10.4190,\n",
       "            0.4968,   -6.2862,  -45.1497,   -7.3668,  -32.7714],\n",
       "        [  -3.4972,   31.2964,  -28.4469,   -3.5423,   19.0190,  -17.2941,\n",
       "          -26.2976,  -15.2658,    5.8858,  -37.4065,  -36.9119,  -33.4379,\n",
       "          -15.3079,  -18.1010,  -20.4883,  -24.0730,  -25.1254,  -32.8994,\n",
       "           -3.7259,  -26.4858,  -11.4578,  -49.4884,  -27.8632,  -28.3417,\n",
       "          -25.3667,  -53.3120,  -26.9595,   -9.6482,  -48.6743],\n",
       "        [ -37.7241,  -78.8876,   92.2101,   29.9073,    7.8852,  -19.0678,\n",
       "          -12.7656,  -54.3811,  -25.9852,  -99.3926, -131.8276,  -40.5023,\n",
       "          -76.2138,  -68.5968,   17.5785,  -41.7020,    5.9910, -155.1064,\n",
       "           -2.1584,  -23.8685, -105.0168, -131.7552, -169.5239,  -63.6790,\n",
       "          -33.7259,   30.3628,   18.0137,  -32.9418,  -46.1787],\n",
       "        [ -43.1520,  -33.1402,   -5.7436,   57.4406,    1.7557,   19.0642,\n",
       "          -22.1134,  -37.9803,    1.8941,  -62.0435,  -65.6781,  -18.7327,\n",
       "          -58.8600,  -51.9612,    9.1509,  -16.7967,  -17.8861,  -85.1006,\n",
       "          -32.6213,  -34.9554,  -63.6837,  -47.0748,  -67.9649,  -39.8730,\n",
       "          -14.0067,  -45.8955,  -17.4450,  -68.1668,  -34.0400],\n",
       "        [  20.2645,   -3.7573,  -31.7393,    7.7063,   38.3035,   12.6444,\n",
       "          -10.7683,  -54.0215,    3.1104,  -60.2857,  -47.1771,  -40.0667,\n",
       "          -27.1068,  -44.0735,    4.6918,  -46.6405,  -24.8986,  -78.0759,\n",
       "          -13.4820,  -15.8677,  -41.8449,  -58.1296,  -65.1022,  -52.7189,\n",
       "          -31.3010,  -25.3980,  -30.9382,  -26.6842,  -79.5053],\n",
       "        [ -22.0952,  -58.9658, -105.9830,  -18.0496,  -29.3041,  124.1692,\n",
       "           -3.5248,  -56.1854,    9.4240,  -25.2544,  -28.9833,  -35.4988,\n",
       "          -70.8722,  -48.1002,   19.5317,    5.3051,  -76.0274, -182.8707,\n",
       "          -76.2867,  -34.2735, -115.1571,  -65.4220,   -6.2840,  -70.9898,\n",
       "           27.2630, -105.3792,  -61.8699, -111.8363,  -30.0586],\n",
       "        [ -45.5425,  -68.9265,  -21.5899,  -46.5346,  -37.3658,  -23.5780,\n",
       "           50.7408,    1.9697,  -24.8994,    9.9693,  -74.0479,  -74.9919,\n",
       "          -14.0402,   -8.9070,  -33.0695,   20.7549,  -14.2521,  -86.5629,\n",
       "          -30.3690,  -52.1317,  -74.5775,  -72.9698,  -76.0749,  -42.2438,\n",
       "           -3.6299,  -76.5106,   -7.8268,  -31.1576,   21.5546],\n",
       "        [ -79.0682,  -60.5479,  -62.9466,  -36.0485,   -3.9023,  -22.2958,\n",
       "           -0.8298,   67.6636,    3.7298,   -2.3941,  -64.3534, -107.1620,\n",
       "          -60.8461,   -4.3149,   -4.6937,   -9.0493,  -33.2198,  -79.1775,\n",
       "          -27.1631,  -46.4314,  -50.6007,  -98.7439,  -93.5880,  -84.1264,\n",
       "          -15.2339,  -74.0611,   -2.5835,  -32.6466,  -23.5821],\n",
       "        [ -17.1750,  -28.7517,  -15.4973,   11.5423,    3.1391,   -9.6922,\n",
       "          -31.5689,   11.4391,   45.2949,  -20.9887,  -25.5823,  -43.8377,\n",
       "          -23.9706,  -26.5642,   -0.2033,  -23.8357,    0.3923,  -34.2096,\n",
       "           -5.0404,   -6.1268,  -51.1531,  -73.9963,  -37.1264,  -30.6386,\n",
       "          -27.7968,  -40.3132,  -13.3891,  -24.0019,  -21.0502],\n",
       "        [ -57.3735,  -77.5826,  -80.2478,  -41.1496,  -32.8216,   -1.7769,\n",
       "           18.5740,   17.4793,    4.0679,   37.1401,  -32.1148,  -75.8709,\n",
       "          -31.6632,  -20.5752,  -25.1517,    1.0556,  -33.9299,  -58.2993,\n",
       "          -34.0643,  -43.5029,  -51.6841,  -63.7677,  -60.3359,  -58.5820,\n",
       "            2.2884,  -84.6368,  -37.4474,  -63.7544,   10.1795],\n",
       "        [ -16.2942,   -7.1062,  -47.9084,   -5.1062,   -9.3271,   -6.8862,\n",
       "          -33.5449,    2.8849,   20.6369,  -13.7747,   25.1132,  -27.9303,\n",
       "          -15.3720,  -12.9233,   -4.6270,  -47.4946,  -43.9679,  -14.9654,\n",
       "          -37.6987,  -18.4538,  -16.1565,  -15.5656,   -2.8320,  -28.5607,\n",
       "          -18.4185,  -25.9136,  -27.5818,  -22.2157,  -15.6174],\n",
       "        [ -14.3960,  -28.6732,    4.4523,   -3.6744,  -23.2675,   -4.5156,\n",
       "          -25.1226,  -63.9155,  -35.8756,  -35.1974,  -35.5191,   33.7056,\n",
       "          -10.6446,  -30.7536,    6.3647,   -5.5987,  -15.0153,  -47.8366,\n",
       "          -16.1412,   -6.2991,  -29.6583,  -26.4652,  -34.9479,  -24.9823,\n",
       "           -8.6046,   11.8569,  -33.0252,  -35.2322,  -23.6163],\n",
       "        [ -19.2906,  -29.0077,  -51.4438,  -40.6730,   -7.1453,  -14.9257,\n",
       "          -22.3207,  -39.2855,  -26.6929,  -13.4920,  -39.1535,  -24.7734,\n",
       "           26.8946,    2.6394,    7.6368,  -10.4370,  -31.9682,  -32.6444,\n",
       "            0.3141,  -11.2440,  -22.5858,  -51.1807,  -32.3045,  -21.1556,\n",
       "          -12.3555,  -42.3637,  -15.4179,  -27.1508,  -21.9223],\n",
       "        [   6.0719,    5.6951,  -15.5015,   -4.6606,    8.5719,  -13.0947,\n",
       "           -6.8226,   -9.8310,   -9.6197,  -20.5780,  -10.7221,  -28.7426,\n",
       "          -11.9582,  -19.1136,  -13.1112,  -12.8741,  -14.7450,  -15.3214,\n",
       "           -5.9018,  -19.9812,   -9.9424,  -24.2552,  -16.2707,  -25.2650,\n",
       "          -27.4515,  -22.5486,  -20.2318,   21.5302,  -27.3902],\n",
       "        [ -28.1322,  -50.4854,  -21.5412,  -39.7145,  -12.1514,  -13.5552,\n",
       "          -29.3294,  -26.8146,  -16.1579,  -22.3861,  -74.5034,  -13.2201,\n",
       "           -2.1288,   46.9998,   -8.9971,   -4.3610,   -5.0214,  -48.3959,\n",
       "           11.7788,   -6.2937,  -46.1846,  -68.5044,  -53.8394,  -21.9598,\n",
       "            5.0506,  -44.8597,   -6.4323,  -36.5095,  -20.4578],\n",
       "        [ -32.7408,  -33.3275,  -18.7237,   19.9147,    5.0788,  -12.7002,\n",
       "          -64.0020,  -61.8851,  -43.4740,  -58.8678,  -72.9089,  -15.7378,\n",
       "          -16.9222,   -4.1685,   51.6844,  -14.4666,  -16.7515,  -80.1632,\n",
       "          -17.0209,  -18.1827,  -32.6830,  -78.1220,  -72.8353,  -60.6894,\n",
       "          -22.2862,   -9.9689,  -19.1631,  -34.0715,  -59.5119],\n",
       "        [ -63.6834, -107.8879,  -25.3204,  -17.4025,  -20.8589,   -1.7443,\n",
       "           -5.0826,   -0.7594,  -35.9012,   -8.5718, -121.8123,  -34.5474,\n",
       "          -46.1184,    7.9195,   -3.3485,   68.3438,   23.4093, -108.2046,\n",
       "          -11.8696,  -30.0791,  -75.0662, -137.1477, -113.8489,  -71.8833,\n",
       "           -7.3156,  -82.3916,   -7.6840,  -54.8829,  -20.6332],\n",
       "        [ -27.1864,  -73.2454,   11.0580,  -20.6611,  -15.7532,  -12.0904,\n",
       "          -22.5368,  -41.7185,  -32.0956,  -35.6986,  -99.2806,  -41.6397,\n",
       "          -51.6123,  -20.6826,    7.9383,   20.8260,   59.0578,  -73.5926,\n",
       "            5.4922,   -1.6204,  -38.6497,  -69.9937,  -98.5748,  -30.7179,\n",
       "           -5.9978,  -24.5115,   27.1883,  -44.1054,  -17.5474],\n",
       "        [ -14.4298,   -5.3820,  -27.8712,  -17.5933,   -7.0497,  -24.2839,\n",
       "          -23.8558,  -24.3535,  -14.2207,  -20.6689,  -19.3727,  -18.2222,\n",
       "           -1.7959,   -9.3706,   -5.3732,  -20.1432,  -12.2809,    5.4448,\n",
       "           -7.4693,   -3.6204,    1.2759,   -9.1172,   -0.6728,   -4.6342,\n",
       "           -5.2756,   -7.2306,   -8.0899,   -7.9206,  -10.3834],\n",
       "        [ -21.0829,  -23.6585,  -16.5260,   -9.7669,  -11.5437,  -10.9918,\n",
       "            0.9763,   -9.0600,  -16.0506,   -2.5822,  -15.1858,  -14.7576,\n",
       "          -10.1440,  -19.3718,   -5.1481,   -3.1229,  -19.5861,  -18.6982,\n",
       "           -6.3665,  -16.5336,  -11.4761,    7.3422,   -7.4035,   -1.5129,\n",
       "            4.7013,  -17.2033,   -6.0179,  -16.3925,   16.1544],\n",
       "        [  -5.9616,  -28.0956,  -28.9238,  -30.1121,   -6.2992,  -17.2761,\n",
       "          -49.8627,  -36.8888,  -12.0309,  -32.1349,  -48.1790,  -20.8967,\n",
       "           -2.2950,    5.7410,    8.1856,  -20.5252,   -6.2073,  -18.2708,\n",
       "           19.0294,   -0.5454,  -10.6122,  -48.9671,  -17.8115,  -14.0310,\n",
       "           -9.1377,   -8.9452,  -17.9852,  -12.9455,  -26.1003],\n",
       "        [   7.8401,  -20.9933,  -12.5248,  -27.0564,  -11.1357,  -15.0853,\n",
       "          -39.9047,  -45.9018,    5.2263,  -22.2339,  -30.4130,    9.3556,\n",
       "           -9.2061,  -25.3434,  -15.4472,  -12.8445,  -14.1466,  -32.1037,\n",
       "           -5.5666,   35.4986,  -31.6320,  -34.2217,  -29.4705,   -3.8114,\n",
       "           -1.5444,    2.3999,  -43.6786,  -10.7614,  -28.3313],\n",
       "        [ -21.6755,  -11.2061,  -28.9631,  -23.1013,  -19.5535,  -37.3936,\n",
       "          -34.7510,  -34.7609,  -25.5521,  -27.6056,  -23.2078,  -13.5926,\n",
       "           -8.6117,  -22.2463,   -3.7951,  -29.3940,  -25.9261,   -8.4689,\n",
       "           -9.0133,   -2.9561,   25.2949,   -7.0398,   -2.3992,   -2.1940,\n",
       "            1.0884,   -2.7693,  -19.0471,  -14.4801,  -16.5319],\n",
       "        [ -12.2738,  -10.3516,  -35.1185,  -13.4895,  -11.7248,  -22.7172,\n",
       "          -14.8711,  -42.4723,  -21.4429,  -30.8705,  -15.8011,  -20.2136,\n",
       "          -10.3583,  -32.8414,    3.0418,  -32.4846,  -41.5494,  -10.4984,\n",
       "          -27.8986,  -13.3063,    0.2465,   20.5789,    1.7366,    0.4661,\n",
       "          -11.1509,    2.4605,   -6.6271,  -16.2542,  -12.0830],\n",
       "        [ -11.3573,  -19.2105,  -66.3038,  -18.0373,  -22.8175,   -3.4086,\n",
       "          -34.8471,  -46.6615,   -7.5405,  -53.8466,   -1.3214,  -35.7771,\n",
       "          -18.5931,  -26.6796,   12.4205,  -40.5705,  -49.6308,  -49.6972,\n",
       "          -47.1923,  -16.4773,  -16.0996,    5.3214,   47.1341,  -30.7488,\n",
       "            4.4268,   -4.7410,  -10.0889,  -41.6665,  -20.5689],\n",
       "        [ -20.0243,  -22.2108,  -23.7158,  -22.1593,   -4.2323,  -23.0276,\n",
       "          -12.6784,  -23.1164,   -5.4489,  -18.0282,  -41.2111,  -13.6399,\n",
       "           -5.5169,  -10.3980,   -6.7172,  -21.7687,  -16.5986,  -13.2476,\n",
       "           -1.4614,   -2.8559,   -3.1864,  -16.1631,  -17.4186,   14.0050,\n",
       "            0.6108,  -11.0217,   -8.1063,   -8.1817,   -6.3883],\n",
       "        [ -28.8606,  -61.3406,  -76.9891,  -35.3036,  -37.1986,   -7.5814,\n",
       "            5.3879,  -53.7138,  -19.9406,   -0.4649,  -20.2584,  -30.8026,\n",
       "          -21.4633,  -25.1135,  -19.8199,  -25.0668,  -44.6510,  -29.2241,\n",
       "          -36.8563,  -12.0913,  -28.3614,   -6.6417,   -3.8381,   -3.9508,\n",
       "           31.2637,  -19.7768,  -28.6823,  -51.7370,   18.3503],\n",
       "        [   5.0342,  -24.3924,  -22.5827,  -11.7993,  -24.2276,  -22.6345,\n",
       "          -28.2361,  -58.5876,  -21.3279,  -45.2104,  -17.2471,  -18.2412,\n",
       "          -11.7160,  -44.0282,    7.2387,  -40.7877,  -31.0205,  -17.9039,\n",
       "          -25.3057,  -15.2152,  -27.5470,   -2.8502,   -4.0985,   -3.7424,\n",
       "          -15.4449,   24.2863,   -8.2497,  -23.0158,  -19.8643]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, preds = torch.max(out_R.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 27.1093,  31.2964,  92.2101,  57.4406,  38.3035, 124.1692,  50.7408,\n",
       "         67.6636,  45.2949,  37.1401,  25.1132,  33.7056,  26.8946,  21.5302,\n",
       "         46.9998,  51.6844,  68.3438,  59.0578,   5.4448,  16.1544,  19.0294,\n",
       "         35.4986,  25.2949,  20.5789,  47.1341,  14.0050,  31.2637,  24.2863],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([19,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 27, 13, 14, 15, 16,\n",
       "        17, 28, 18, 19, 20, 21, 22, 23, 24, 25], device='cuda:0')"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  5,  6,  7,  8,  9, 10, 11, 12, 13, 15, 14, 16, 17, 18,\n",
       "        19, 21, 20, 22, 23, 24, 25, 26, 27, 28])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lables_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(45.9709, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
