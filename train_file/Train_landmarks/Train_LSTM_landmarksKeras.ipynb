{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1x0</th>\n",
       "      <th>1y0</th>\n",
       "      <th>1z0</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1y1</th>\n",
       "      <th>1z1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1y2</th>\n",
       "      <th>1z2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>...</th>\n",
       "      <th>1z18</th>\n",
       "      <th>1x19</th>\n",
       "      <th>1y19</th>\n",
       "      <th>1z19</th>\n",
       "      <th>1x20</th>\n",
       "      <th>1y20</th>\n",
       "      <th>1z20</th>\n",
       "      <th>frame</th>\n",
       "      <th>sign</th>\n",
       "      <th>sign_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.792746</td>\n",
       "      <td>0.990288</td>\n",
       "      <td>-8.256451e-07</td>\n",
       "      <td>0.734886</td>\n",
       "      <td>0.911677</td>\n",
       "      <td>-0.003520</td>\n",
       "      <td>0.711027</td>\n",
       "      <td>0.794658</td>\n",
       "      <td>-0.004054</td>\n",
       "      <td>0.700255</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029235</td>\n",
       "      <td>0.845639</td>\n",
       "      <td>0.630521</td>\n",
       "      <td>-0.024903</td>\n",
       "      <td>0.818636</td>\n",
       "      <td>0.681482</td>\n",
       "      <td>-0.014796</td>\n",
       "      <td>1</td>\n",
       "      <td>YES</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.799704</td>\n",
       "      <td>0.992832</td>\n",
       "      <td>-8.117081e-07</td>\n",
       "      <td>0.739026</td>\n",
       "      <td>0.895418</td>\n",
       "      <td>0.003122</td>\n",
       "      <td>0.713416</td>\n",
       "      <td>0.788441</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>0.703935</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023513</td>\n",
       "      <td>0.850635</td>\n",
       "      <td>0.628874</td>\n",
       "      <td>-0.019362</td>\n",
       "      <td>0.824483</td>\n",
       "      <td>0.688885</td>\n",
       "      <td>-0.008970</td>\n",
       "      <td>2</td>\n",
       "      <td>YES</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.799565</td>\n",
       "      <td>0.993079</td>\n",
       "      <td>-8.044564e-07</td>\n",
       "      <td>0.740635</td>\n",
       "      <td>0.893880</td>\n",
       "      <td>0.001804</td>\n",
       "      <td>0.713768</td>\n",
       "      <td>0.788145</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>0.704011</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025401</td>\n",
       "      <td>0.853576</td>\n",
       "      <td>0.628154</td>\n",
       "      <td>-0.021274</td>\n",
       "      <td>0.826121</td>\n",
       "      <td>0.687863</td>\n",
       "      <td>-0.011128</td>\n",
       "      <td>3</td>\n",
       "      <td>YES</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.798942</td>\n",
       "      <td>0.993288</td>\n",
       "      <td>-8.204698e-07</td>\n",
       "      <td>0.741771</td>\n",
       "      <td>0.896844</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>0.716491</td>\n",
       "      <td>0.788728</td>\n",
       "      <td>-0.000861</td>\n",
       "      <td>0.706110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026144</td>\n",
       "      <td>0.853186</td>\n",
       "      <td>0.628007</td>\n",
       "      <td>-0.021998</td>\n",
       "      <td>0.826591</td>\n",
       "      <td>0.688785</td>\n",
       "      <td>-0.011470</td>\n",
       "      <td>4</td>\n",
       "      <td>YES</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.799430</td>\n",
       "      <td>0.997525</td>\n",
       "      <td>-8.401622e-07</td>\n",
       "      <td>0.740387</td>\n",
       "      <td>0.895666</td>\n",
       "      <td>0.004254</td>\n",
       "      <td>0.715142</td>\n",
       "      <td>0.788283</td>\n",
       "      <td>0.005445</td>\n",
       "      <td>0.705099</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022941</td>\n",
       "      <td>0.853379</td>\n",
       "      <td>0.629244</td>\n",
       "      <td>-0.018652</td>\n",
       "      <td>0.826039</td>\n",
       "      <td>0.689840</td>\n",
       "      <td>-0.008591</td>\n",
       "      <td>5</td>\n",
       "      <td>YES</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0.626633</td>\n",
       "      <td>0.777197</td>\n",
       "      <td>6.241039e-08</td>\n",
       "      <td>0.541895</td>\n",
       "      <td>0.721393</td>\n",
       "      <td>0.040732</td>\n",
       "      <td>0.497637</td>\n",
       "      <td>0.648182</td>\n",
       "      <td>0.036825</td>\n",
       "      <td>0.451215</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.105235</td>\n",
       "      <td>0.519936</td>\n",
       "      <td>0.641065</td>\n",
       "      <td>-0.093330</td>\n",
       "      <td>0.554812</td>\n",
       "      <td>0.663161</td>\n",
       "      <td>-0.080579</td>\n",
       "      <td>16</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>0.636006</td>\n",
       "      <td>0.802810</td>\n",
       "      <td>2.072078e-07</td>\n",
       "      <td>0.552586</td>\n",
       "      <td>0.742736</td>\n",
       "      <td>0.011503</td>\n",
       "      <td>0.501454</td>\n",
       "      <td>0.657794</td>\n",
       "      <td>-0.000170</td>\n",
       "      <td>0.457878</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.102227</td>\n",
       "      <td>0.521275</td>\n",
       "      <td>0.638136</td>\n",
       "      <td>-0.092558</td>\n",
       "      <td>0.553049</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>-0.078551</td>\n",
       "      <td>17</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>0.620894</td>\n",
       "      <td>0.760771</td>\n",
       "      <td>3.646648e-07</td>\n",
       "      <td>0.547273</td>\n",
       "      <td>0.718012</td>\n",
       "      <td>0.008708</td>\n",
       "      <td>0.502508</td>\n",
       "      <td>0.641607</td>\n",
       "      <td>-0.003569</td>\n",
       "      <td>0.458056</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108910</td>\n",
       "      <td>0.528940</td>\n",
       "      <td>0.636936</td>\n",
       "      <td>-0.103565</td>\n",
       "      <td>0.561864</td>\n",
       "      <td>0.664369</td>\n",
       "      <td>-0.092096</td>\n",
       "      <td>18</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>0.646680</td>\n",
       "      <td>0.796605</td>\n",
       "      <td>2.927184e-07</td>\n",
       "      <td>0.561233</td>\n",
       "      <td>0.734687</td>\n",
       "      <td>0.016453</td>\n",
       "      <td>0.513528</td>\n",
       "      <td>0.648054</td>\n",
       "      <td>0.006548</td>\n",
       "      <td>0.469913</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096801</td>\n",
       "      <td>0.533951</td>\n",
       "      <td>0.625852</td>\n",
       "      <td>-0.086504</td>\n",
       "      <td>0.564234</td>\n",
       "      <td>0.656142</td>\n",
       "      <td>-0.072171</td>\n",
       "      <td>19</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>0.631218</td>\n",
       "      <td>0.732334</td>\n",
       "      <td>2.654304e-07</td>\n",
       "      <td>0.559902</td>\n",
       "      <td>0.686823</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>0.515233</td>\n",
       "      <td>0.619968</td>\n",
       "      <td>-0.010117</td>\n",
       "      <td>0.473329</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107406</td>\n",
       "      <td>0.535050</td>\n",
       "      <td>0.622082</td>\n",
       "      <td>-0.100305</td>\n",
       "      <td>0.565049</td>\n",
       "      <td>0.647579</td>\n",
       "      <td>-0.088070</td>\n",
       "      <td>20</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1x0       1y0           1z0       1x1       1y1       1z1       1x2  \\\n",
       "0    0.792746  0.990288 -8.256451e-07  0.734886  0.911677 -0.003520  0.711027   \n",
       "1    0.799704  0.992832 -8.117081e-07  0.739026  0.895418  0.003122  0.713416   \n",
       "2    0.799565  0.993079 -8.044564e-07  0.740635  0.893880  0.001804  0.713768   \n",
       "3    0.798942  0.993288 -8.204698e-07  0.741771  0.896844 -0.000105  0.716491   \n",
       "4    0.799430  0.997525 -8.401622e-07  0.740387  0.895666  0.004254  0.715142   \n",
       "..        ...       ...           ...       ...       ...       ...       ...   \n",
       "595  0.626633  0.777197  6.241039e-08  0.541895  0.721393  0.040732  0.497637   \n",
       "596  0.636006  0.802810  2.072078e-07  0.552586  0.742736  0.011503  0.501454   \n",
       "597  0.620894  0.760771  3.646648e-07  0.547273  0.718012  0.008708  0.502508   \n",
       "598  0.646680  0.796605  2.927184e-07  0.561233  0.734687  0.016453  0.513528   \n",
       "599  0.631218  0.732334  2.654304e-07  0.559902  0.686823  0.004743  0.515233   \n",
       "\n",
       "          1y2       1z2       1x3  ...      1z18      1x19      1y19  \\\n",
       "0    0.794658 -0.004054  0.700255  ... -0.029235  0.845639  0.630521   \n",
       "1    0.788441  0.004467  0.703935  ... -0.023513  0.850635  0.628874   \n",
       "2    0.788145  0.001861  0.704011  ... -0.025401  0.853576  0.628154   \n",
       "3    0.788728 -0.000861  0.706110  ... -0.026144  0.853186  0.628007   \n",
       "4    0.788283  0.005445  0.705099  ... -0.022941  0.853379  0.629244   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "595  0.648182  0.036825  0.451215  ... -0.105235  0.519936  0.641065   \n",
       "596  0.657794 -0.000170  0.457878  ... -0.102227  0.521275  0.638136   \n",
       "597  0.641607 -0.003569  0.458056  ... -0.108910  0.528940  0.636936   \n",
       "598  0.648054  0.006548  0.469913  ... -0.096801  0.533951  0.625852   \n",
       "599  0.619968 -0.010117  0.473329  ... -0.107406  0.535050  0.622082   \n",
       "\n",
       "         1z19      1x20      1y20      1z20  frame  sign  sign_n  \n",
       "0   -0.024903  0.818636  0.681482 -0.014796      1   YES       1  \n",
       "1   -0.019362  0.824483  0.688885 -0.008970      2   YES       1  \n",
       "2   -0.021274  0.826121  0.687863 -0.011128      3   YES       1  \n",
       "3   -0.021998  0.826591  0.688785 -0.011470      4   YES       1  \n",
       "4   -0.018652  0.826039  0.689840 -0.008591      5   YES       1  \n",
       "..        ...       ...       ...       ...    ...   ...     ...  \n",
       "595 -0.093330  0.554812  0.663161 -0.080579     16    NO       0  \n",
       "596 -0.092558  0.553049  0.663608 -0.078551     17    NO       0  \n",
       "597 -0.103565  0.561864  0.664369 -0.092096     18    NO       0  \n",
       "598 -0.086504  0.564234  0.656142 -0.072171     19    NO       0  \n",
       "599 -0.100305  0.565049  0.647579 -0.088070     20    NO       0  \n",
       "\n",
       "[600 rows x 66 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"D:\\\\project\\\\dataset\\\\gen_land_marks_dataset\\\\FrameLM_.csv\"\n",
    "\n",
    "\n",
    "data = pd.read_csv(data_path)\n",
    "data['sign_n'] = data['sign'].astype('category').cat.codes\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypints_array = data.values[:,:63].reshape(30, 20, 21,3)\n",
    "lable_array = data.values[:,-1].reshape(30, 20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 20, 21, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypints_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keypints_array = keypints_array.reshape(80, 15, 126)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lable_array_ = np.zeros((30, 2))\n",
    "for i in range(keypints_array.shape[0]):\n",
    "    lable_array_[i][lable_array[i][0][0]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lable_array_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(keypints_array, lable_array_, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypints_array = keypints_array.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(20, 21,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'Adam',loss='categorical_crossentropy',metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 18, 19, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 9, 9, 32)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 3, 3, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               73856     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,506\n",
      "Trainable params: 93,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.9604e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.8059e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.6469e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.4880e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.3467e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.1966e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.0597e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.9317e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.7948e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.6580e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.5343e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.4063e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.2783e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1679e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.0487e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.9339e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.8147e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7131e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.5984e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.5012e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.3864e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.2937e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.1966e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.0995e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.9847e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.9140e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.8257e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.7286e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.6403e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.5564e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.4814e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.3975e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.3180e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.2341e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.1591e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.0840e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.0134e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.9383e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.8765e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.8103e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.7308e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 5.6602e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.6028e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5.5365e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.4659e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.4129e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.3379e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.2849e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.2275e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.1745e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.1127e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.0641e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.0156e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.9449e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.8964e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.8478e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.7948e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.7418e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.6888e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.6403e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.5873e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.5432e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.4946e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.4504e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.4107e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.3621e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.3180e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.2650e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.2253e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.1899e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.1458e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.1105e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.0752e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.0310e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.9957e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.9515e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.9074e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.8765e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.8367e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.8102e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.7705e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.7484e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.6999e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.6690e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.6425e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.6116e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.5630e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.5365e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.5056e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.4791e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.4438e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.4173e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.3864e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.3555e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.3334e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.2937e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.2716e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.2451e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.2098e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.1921e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.1612e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.1392e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.1082e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.0818e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.0553e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.0332e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.0067e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.9846e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.9626e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.9316e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.9228e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.8919e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.8654e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.8433e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.8257e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.8124e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.7904e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.7683e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.7418e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.7241e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.7065e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.6712e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.6535e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.6314e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.6093e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.5917e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.5784e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.5608e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.5431e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.5166e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.4990e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.4813e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.4636e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.4416e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.4239e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.4018e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3886e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3798e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3621e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3400e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3312e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.3179e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3047e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2870e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.2650e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2517e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2341e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.2164e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.1943e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.1722e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.1590e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.1458e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.1325e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.1193e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.0972e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.0839e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.0707e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.0575e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.0398e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.0265e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.0177e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.0045e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.9912e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.9824e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.9736e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.9515e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.9471e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.9294e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.9206e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.9073e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.8941e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.8808e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.8720e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.8676e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.8455e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.8367e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.8323e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.8235e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.8146e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.7970e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.7837e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.7705e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.7616e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.7484e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.7352e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.7175e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.7087e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6998e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6954e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.6778e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.6645e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.6557e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.6513e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6380e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.6292e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.6204e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.6115e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6027e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5939e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5895e-06 - categorical_accuracy: 1.0000\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 18, 19, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 9, 9, 32)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 3, 3, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               73856     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,506\n",
      "Trainable params: 93,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs = 200)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.9999976e-01, 2.1595901e-07],\n",
       "       [1.2741646e-07, 9.9999988e-01],\n",
       "       [9.9999905e-01, 9.1920612e-07]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.8468,  0.9027,  0.7710,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.8485,  0.9221,  0.7710,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.8405,  0.9277,  0.7710,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0989,  0.9731,  0.7710,  ...,  0.9065,  0.5294, -0.0606],\n",
       "         [ 0.1095,  0.9907,  0.7710,  ...,  0.9556,  0.5438, -0.0664],\n",
       "         [ 0.1116,  1.0000,  0.7710,  ...,  0.9860,  0.5429, -0.0835]]),\n",
       " 0.0)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset[0]\n",
    "lable_array_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#test_dataset = MyDataset(test_data)\n",
    "TrainDataLoader = DataLoader(dataset, batch_size=1)\n",
    "#TestDataLoader = DataLoader(v, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMmodel(nn.Module):\n",
    "    def __init__(self, num_classes ):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=126, hidden_size=500, num_layers=1, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.linear = nn.Linear(500, num_classes)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "model = LSTMmodel(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
